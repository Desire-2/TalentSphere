version: '3.8'

services:
  # TalentSphere Backend (Ultra-Optimized)
  backend:
    build: 
      context: .
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    ports:
      - "${PORT:-5001}:5001"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - SECRET_KEY=${SECRET_KEY}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - FLASK_ENV=${FLASK_ENV:-production}
      - REDIS_URL=redis://redis:6379/0
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:3000,http://localhost:5173}
      
      # Performance Optimization Settings
      - SLOW_QUERY_THRESHOLD=0.5
      - SLOW_REQUEST_THRESHOLD=1.0
      - DB_POOL_SIZE=15
      - DB_MAX_OVERFLOW=25
      - DB_POOL_TIMEOUT=20
      - DB_POOL_RECYCLE=1800
      - SQL_ECHO=false
      - SQL_ECHO_POOL=false
      
      # Gunicorn Performance Settings
      - GUNICORN_WORKERS=4
      - GUNICORN_WORKER_CONNECTIONS=1000
      - GUNICORN_MAX_REQUESTS=2000
      - GUNICORN_MAX_REQUESTS_JITTER=200
      - GUNICORN_TIMEOUT=60
      - GUNICORN_KEEPALIVE=5
      - GUNICORN_PRELOAD_APP=true
      - GUNICORN_WORKER_CLASS=sync
      
      # Cache Settings
      - CACHE_TTL_SHORT=300
      - CACHE_TTL_MEDIUM=1800
      - CACHE_TTL_LONG=3600
      - ENABLE_RESPONSE_COMPRESSION=true
      
      # Memory Management
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - MALLOC_ARENA_MAX=2
    
    depends_on:
      redis:
        condition: service_healthy
    
    volumes:
      - ./src/database:/app/src/database  # Persist SQLite database if used
      - backend-cache:/tmp/flask-cache   # Temporary cache storage
    
    networks:
      - talentsphere-network
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    
    # Resource limits for better performance
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2.0'
        reservations:
          memory: 512M
          cpus: '1.0'
    
    # Optimize container for performance
    security_opt:
      - no-new-privileges:true
    
    # Use init system for proper signal handling
    init: true

  # Redis Cache (High Performance Configuration)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    
    volumes:
      - redis-data:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf:ro
    
    networks:
      - talentsphere-network
    
    restart: unless-stopped
    
    # High-performance Redis configuration
    command: >
      redis-server /usr/local/etc/redis/redis.conf
      --appendonly yes
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --tcp-keepalive 300
      --timeout 0
      --tcp-backlog 511
      --databases 16
      --stop-writes-on-bgsave-error no
      --rdbcompression yes
      --rdbchecksum yes
      --dir /data
    
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    
    deploy:
      resources:
        limits:
          memory: 600M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'

  # Nginx Reverse Proxy (Performance Enhancement)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx-cache:/var/cache/nginx
      - nginx-logs:/var/log/nginx
    
    depends_on:
      backend:
        condition: service_healthy
    
    networks:
      - talentsphere-network
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    
    profiles:
      - production
    
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'

  # Database Connection Pool Monitor
  db-monitor:
    build: .
    command: ["python", "-c", "
      import time; 
      import sys; 
      sys.path.insert(0, '.'); 
      from src.utils.performance import ConnectionPoolMonitor; 
      while True: 
        stats = ConnectionPoolMonitor.get_pool_stats(); 
        print(f'Pool Stats: {stats}'); 
        time.sleep(30)
    "]
    
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis:6379/0
    
    depends_on:
      - backend
    
    networks:
      - talentsphere-network
    
    profiles:
      - monitoring
    
    restart: "no"

  # Performance Monitoring Dashboard
  monitoring:
    build: .
    ports:
      - "5002:5002"
    
    command: ["python", "monitor_performance.py", "--port", "5002"]
    
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis:6379/0
      - FLASK_ENV=development
    
    depends_on:
      backend:
        condition: service_healthy
      redis:
        condition: service_healthy
    
    networks:
      - talentsphere-network
    
    profiles:
      - monitoring
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5002/health"]
      interval: 60s
      timeout: 10s
      retries: 2

  # Log Aggregator (for production monitoring)
  log-aggregator:
    image: busybox
    command: >
      sh -c "
        mkdir -p /logs &&
        tail -f /logs/backend.log /logs/nginx.log /logs/redis.log 2>/dev/null || 
        echo 'Waiting for log files...' && sleep 30
      "
    
    volumes:
      - backend-logs:/logs/backend:ro
      - nginx-logs:/logs/nginx:ro
      - redis-data:/logs/redis:ro
    
    profiles:
      - logging
    
    restart: unless-stopped

volumes:
  redis-data:
    driver: local
  backend-cache:
    driver: local
  backend-logs:
    driver: local
  nginx-logs:
    driver: local

networks:
  talentsphere-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16